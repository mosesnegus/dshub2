{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import random\n",
    "\n",
    "from mongo_aggregation_verbs import *\n",
    "\n",
    "mongo_client = MongoClient('18.236.138.158', 27016)\n",
    "database_reference = mongo_client.twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_reference.collection_names()\n",
    "\n",
    "collection_reference = database_reference.instructor_test_group\n",
    "\n",
    "test_group = database_reference.instructor_test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_empty_url_arrays = { MATCH : { \"entities.urls\" : [] } }\n",
    "\n",
    "list(test_group.aggregate(\n",
    "    [\n",
    "        match_empty_url_arrays,\n",
    "        { COUNT : \"text\" }\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_hashtags = ['job', 'jobs', 'hiring', 'careerarc']\n",
    "location_hashtags = ['california', 'losangeles', 'la', 'santamonica', 'glendale', 'paloalto']\n",
    "match_not_in_bad = { MATCH : { \"text\" : { \"$in\" : job_hashtags + location_hashtags } } }\n",
    "project_to_text_keep_id = { PROJECT : { \"text\" : \"$entities.hashtags.text\" } }\n",
    "project_to_id = { PROJECT : { \"_id\" : 1 } }\n",
    "\n",
    "bad_ids = list(test_group.aggregate(\n",
    "    [\n",
    "        match_non_empty_hashtag_arrays,\n",
    "        project_to_text_keep_id,\n",
    "        unwind_text,\n",
    "        project_to_lower,\n",
    "        match_not_in_bad,\n",
    "        project_to_id\n",
    "    ]\n",
    "))\n",
    "bad_ids[:10], len(bad_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [bad_id['_id'] for bad_id in bad_ids]\n",
    "bad_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_bad_ids = { \"$nin\" : bad_ids }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_bad_ids_and_no_url = { \n",
    "    \"_id\"           : not_in_bad_ids, \n",
    "    \"entities.urls\" : []\n",
    "}\n",
    "\n",
    "just_the_text = {\n",
    "    \"text\" : 1,\n",
    "    \"_id\"  : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group.find_one(\n",
    "    not_in_bad_ids_and_no_url,\n",
    "    just_the_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur  = test_group.find(\n",
    "    not_in_bad_ids_and_no_url,\n",
    "    just_the_text\n",
    ")\n",
    "\n",
    "tweets = list(cur)\n",
    "tweet_text = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_text.text = tweet_text.text.str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(tweet_text.text)\n",
    "word_occurence = tfidf.transform(tweet_text.text).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfidf.get_feature_names()\n",
    "word_sample = random.sample(words, 20)\n",
    "word_occurence_m = pd.DataFrame(word_occurence, columns=words)\n",
    "word_occurence_m[word_sample].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=10, learning_method='batch')\n",
    "lda.fit(word_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.DataFrame(lda.components_, columns=words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_topic(lda_df, index, threshold):\n",
    "    return (lda_df[lda_df[index] > threshold][index]\n",
    "            .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 8, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 9, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
